{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入\n",
    "X = np.array([[1,0,0],\n",
    "              [1,0,1],\n",
    "              [1,1,0],\n",
    "              [1,1,1]])\n",
    "#标签\n",
    "Y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]])\n",
    "#3-10-1\n",
    "#取值范围为-1到1\n",
    "V = np.random.random([3,10])*2-1\n",
    "W = np.random.random([10,1])*2-1\n",
    "\n",
    "lr = 0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "#权值调整函数\n",
    "def update():\n",
    "    global V,W\n",
    "    #求每一层的输出\n",
    "    L1 = sigmoid(np.dot(X,V))\n",
    "    L2 = sigmoid(np.dot(L1,W))\n",
    "    #求每一层的学习信号\n",
    "    L2_delta = (Y - L2)*dsigmoid(L2)#这里参照 BP算法推导的结果来写\n",
    "    L1_delta = L2_delta.dot(W.T)*dsigmoid(L1)\n",
    "    #求每一层权值的变化\n",
    "    delta_W = lr * L1.T.dot(L2_delta)\n",
    "    delta_V = lr * X.T.dot(L1_delta)\n",
    "    #改变权值\n",
    "    W += delta_W\n",
    "    V += delta_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.17514516398805935\n",
      "loss: 0.12240679082525865\n",
      "loss: 0.1119960967765083\n",
      "loss: 0.08450626826477783\n",
      "loss: 0.046977587420147286\n",
      "loss: 0.022593253994901433\n",
      "loss: 0.012154625252695284\n",
      "loss: 0.007542636842307907\n",
      "loss: 0.005197775564250029\n",
      "loss: 0.003850814921114904\n",
      "loss: 0.003002498714765347\n",
      "loss: 0.0024301621878155383\n",
      "loss: 0.0020232255350246314\n",
      "loss: 0.0017218044859309352\n",
      "loss: 0.0014911339325824869\n",
      "loss: 0.001309860089871562\n",
      "loss: 0.0011642436203346648\n",
      "loss: 0.0010450953557328492\n",
      "loss: 0.0009460649068175162\n",
      "loss: 0.0008626391672693155\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    update()#更新权值\n",
    "    if i%500 == 0:\n",
    "        L1 = sigmoid(np.dot(X,V))\n",
    "        L2 = sigmoid(np.dot(L1,W))  \n",
    "        loss = np.mean(np.square(Y-L2)/2)\n",
    "        print('loss:',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03408223]\n",
      " [0.95735786]\n",
      " [0.96460371]\n",
      " [0.04583081]]\n"
     ]
    }
   ],
   "source": [
    "L1 = sigmoid(np.dot(X,V))\n",
    "L2 = sigmoid(np.dot(L1,W))\n",
    "print(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#转换为 整数\n",
    "def judge(x):\n",
    "    if x>=0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for i in map(judge,L2):#将L2中的值 一个个放到judge中运行\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
