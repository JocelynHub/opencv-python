{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# from keras import mnist\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist = tf.keras.datasets.mnist\n",
    "# (x_data,y_data),(x_test,y_test) = mnist.load_data()\n",
    "# #定义批次大小\n",
    "# batch_size = 64\n",
    "# #计算一个周期共有多少个批次\n",
    "# n_batch = x_data.shape[0] // batch_size\n",
    "# print(n_batch)\n",
    "\n",
    "\n",
    "# #构建神经网络 拟合非线性分布\n",
    "# x = tf.compat.v1.placeholder(tf.float32,[None,784])#输入，Nx1的数据\n",
    "# y = tf.compat.v1.placeholder(tf.float32,[None,10])#标签，Nx1的数据\n",
    "\n",
    "# #神经网络结构 784-10\n",
    "# W = tf.Variable(tf.compat.v1.truncated_normal([784,10],stddev = 0.1))\n",
    "# b = tf.Variable(tf.zeros([10])+0.1)#初始化为常数 为0 或者 0.1\n",
    "\n",
    "# wx_plus_b = tf.matmul(x,W) + b                \n",
    "# prediction = tf.compat.v1.nn.softmax(wx_plus_b)\n",
    "\n",
    "# #定义代价函数\n",
    "# # loss = tf.losses.mean_squared_error(y,prediction)#这里是注意点，如果用这个结果会是一条直线\n",
    "# # loss = tf.compat.v1.losses.mean_squared_error(y,prediction)#这个是正确的二次代价函数\n",
    "# #这里是交叉熵代价函数，如果激活函数用的是sigmoid的话，需要考虑的就是sigmoid的交叉熵代价函数        \n",
    "# loss = tf.compat.v1.losses.softmax_cross_entropy(y,prediction)\n",
    "\n",
    "# #使用梯度下降法 最小化loss\n",
    "# train = tf.compat.v1.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "                \n",
    "# #将结果存放在一个bool型列表中\n",
    "# correction_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "# #求准确率\n",
    "# accuracy = tf.reduce_mean(tf.cast(correction_prediction,tf.float32))\n",
    "\n",
    "\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     sess.run(tf.compat.v1.global_variables_initializer())\n",
    "    \n",
    "#     for epoch in range(21):\n",
    "#         for batch in range(n_batch):\n",
    "#             #获取一个批次的数据和标签\n",
    "#             batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "#             sess.run(train,feed_dict = {x:batch_xs,y:batch_ys})#这里才是真正的计算\n",
    "        \n",
    "#         #获取预测值 进行比较\n",
    "#         acc = sess.run(accuracy,feed_dict = {x:x_test,y:y_test})\n",
    "#         print(\"Iter \"+str(epoch)+\",Testing Accuracy \"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "#进行数据转换，并归一化\n",
    "#将（60000，28，28）-->(60000,784)\n",
    "x_train = x_train.reshape(x_train.shape[0],-1)/255.0\n",
    "x_test = x_test.reshape(x_test.shape[0],-1)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "#转换为one hot模式\n",
    "y_train = np_utils.to_categorical(y_train,num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes=10)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 2s 975us/step - loss: 0.7802 - accuracy: 0.8126\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 2s 969us/step - loss: 0.4570 - accuracy: 0.8795\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 971us/step - loss: 0.4033 - accuracy: 0.8910\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 965us/step - loss: 0.3766 - accuracy: 0.8970\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 2s 989us/step - loss: 0.3598 - accuracy: 0.9012\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 2s 976us/step - loss: 0.3478 - accuracy: 0.9032\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 2s 987us/step - loss: 0.3387 - accuracy: 0.9057\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 2s 984us/step - loss: 0.3317 - accuracy: 0.9075\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 992us/step - loss: 0.3258 - accuracy: 0.9092\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 981us/step - loss: 0.3209 - accuracy: 0.9106\n",
      "313/313 [==============================] - 0s 903us/step - loss: 0.3059 - accuracy: 0.9161\n",
      "\n",
      "test loss: 0.3059191107749939\n",
      "accuracy: 0.916100025177002\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建模型:输入784个神经元，输出10个神经元 784-10\n",
    "model = Sequential([\n",
    "        Dense(units=10, input_dim=784, bias_initializer='one', activation='softmax')\n",
    "    ])\n",
    "\n",
    "# 定义优化器，loss function, 训练过程中的准确率\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = 'categorical_crossentropy', #  或者使用loss = keras.losses.categorical_crossentropy,\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "# 进行模型训练\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "\n",
    "# 评估模型\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('\\ntest loss:', loss)\n",
    "print('accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
